model:
  # Default: dummy model for local development (no API calls).
  # Switch provider to "openai" when you have a working key and quota.
  provider: dummy
  name: gpt-4.1-mini
  temperature: 0.2
  max_tokens: 512

retrieval:
  embedding_model: all-MiniLM-L6-v2
  chunk_size: 400
  chunk_overlap: 50
  top_k: 4

data:
  docs_path: data/docs

logging:
  level: info

